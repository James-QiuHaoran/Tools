# XLA

## Run XLA on GPUs

https://github.com/pytorch/xla/blob/master/docs/gpu.md

Set environment variables: `export GPU_NUM_DEVICES=1 PJRT_DEVICE=CUDA`

If you want to run on the second GPU: `export CUDA_VISIBLE_DEVICES=1`
